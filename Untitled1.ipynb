{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ktrain\n",
      "  Downloading ktrain-0.25.4.tar.gz (25.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.3 MB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-learn==0.23.2\n",
      "  Downloading scikit-learn-0.23.2.tar.gz (7.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.2 MB 2.9 MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting matplotlib>=3.0.0\n",
      "  Downloading matplotlib-3.3.4-cp39-cp39-macosx_10_9_x86_64.whl (8.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.5 MB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas>=1.0.1\n",
      "  Downloading pandas-1.2.3-cp39-cp39-macosx_10_9_x86_64.whl (10.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.7 MB 5.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fastprogress>=0.1.21\n",
      "  Downloading fastprogress-1.0.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ktrain) (2.25.1)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ktrain) (1.0.1)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ktrain) (20.9)\n",
      "Requirement already satisfied: ipython in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ktrain) (7.20.0)\n",
      "Collecting langdetect\n",
      "  Using cached langdetect-1.0.8.tar.gz (981 kB)\n",
      "Collecting jieba\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.2 MB 3.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cchardet\n",
      "  Downloading cchardet-2.1.7-cp39-cp39-macosx_10_9_x86_64.whl (124 kB)\n",
      "\u001b[K     |████████████████████████████████| 124 kB 5.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting syntok\n",
      "  Downloading syntok-1.3.1.tar.gz (23 kB)\n",
      "Collecting seqeval==0.0.19\n",
      "  Downloading seqeval-0.0.19.tar.gz (30 kB)\n",
      "Collecting transformers<4.0,>=3.1.0\n",
      "  Downloading transformers-3.5.1-py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 4.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.95-cp39-cp39-macosx_10_6_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras_bert>=0.86.0\n",
      "  Downloading keras-bert-0.86.0.tar.gz (26 kB)\n",
      "Collecting networkx>=2.3\n",
      "  Downloading networkx-2.5-py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting whoosh\n",
      "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
      "\u001b[K     |████████████████████████████████| 468 kB 934 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting scipy>=0.19.1\n",
      "  Using cached scipy-1.6.1-cp39-cp39-macosx_10_9_x86_64.whl (30.9 MB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn==0.23.2->ktrain) (1.20.1)\n",
      "Collecting Keras>=2.2.4\n",
      "  Using cached Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Collecting pyyaml\n",
      "  Downloading PyYAML-5.4.1-cp39-cp39-macosx_10_9_x86_64.whl (259 kB)\n",
      "\u001b[K     |████████████████████████████████| 259 kB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting h5py\n",
      "  Downloading h5py-3.2.1-cp39-cp39-macosx_10_9_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 4.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-transformer>=0.38.0\n",
      "  Downloading keras-transformer-0.38.0.tar.gz (11 kB)\n",
      "Collecting keras-pos-embd>=0.11.0\n",
      "  Downloading keras-pos-embd-0.11.0.tar.gz (5.9 kB)\n",
      "Collecting keras-multi-head>=0.27.0\n",
      "  Downloading keras-multi-head-0.27.0.tar.gz (14 kB)\n",
      "Collecting keras-layer-normalization>=0.14.0\n",
      "  Downloading keras-layer-normalization-0.14.0.tar.gz (4.3 kB)\n",
      "Collecting keras-position-wise-feed-forward>=0.6.0\n",
      "  Downloading keras-position-wise-feed-forward-0.6.0.tar.gz (4.4 kB)\n",
      "Collecting keras-embed-sim>=0.8.0\n",
      "  Downloading keras-embed-sim-0.8.0.tar.gz (4.1 kB)\n",
      "Collecting keras-self-attention==0.46.0\n",
      "  Downloading keras-self-attention-0.46.0.tar.gz (10 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib>=3.0.0->ktrain) (2.4.7)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp39-cp39-macosx_10_9_x86_64.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 551 kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting python-dateutil>=2.1\n",
      "  Using cached python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-8.1.2-cp39-cp39-macosx_10_10_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /Users/anjaneyatripathi/Library/Python/3.9/lib/python/site-packages (from cycler>=0.10->matplotlib>=3.0.0->ktrain) (1.15.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from networkx>=2.3->ktrain) (4.4.2)\n",
      "Collecting pytz>=2017.3\n",
      "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "\u001b[K     |████████████████████████████████| 510 kB 3.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Using cached sacremoses-0.0.43.tar.gz (883 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers<4.0,>=3.1.0->ktrain) (2020.11.13)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers<4.0,>=3.1.0->ktrain) (4.56.1)\n",
      "Requirement already satisfied: filelock in /Users/anjaneyatripathi/Library/Python/3.9/lib/python/site-packages (from transformers<4.0,>=3.1.0->ktrain) (3.0.12)\n",
      "Collecting tokenizers==0.9.3\n",
      "  Downloading tokenizers-0.9.3.tar.gz (172 kB)\n",
      "\u001b[K     |████████████████████████████████| 172 kB 5.1 MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting protobuf\n",
      "  Downloading protobuf-3.15.5-cp39-cp39-macosx_10_9_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 8.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.91.tar.gz (500 kB)\n",
      "\u001b[K     |████████████████████████████████| 500 kB 3.9 MB/s eta 0:00:01\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /Library/Frameworks/Python.framework/Versions/3.9/bin/python3 -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/sr/f97fk8y57w5_72ntv41mhk8c0000gn/T/pip-install-xpfagqd4/sentencepiece_bea06650baad40fba646bd5f8b2ee544/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/sr/f97fk8y57w5_72ntv41mhk8c0000gn/T/pip-install-xpfagqd4/sentencepiece_bea06650baad40fba646bd5f8b2ee544/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/sr/f97fk8y57w5_72ntv41mhk8c0000gn/T/pip-pip-egg-info-r4zsdfbx\n",
      "         cwd: /private/var/folders/sr/f97fk8y57w5_72ntv41mhk8c0000gn/T/pip-install-xpfagqd4/sentencepiece_bea06650baad40fba646bd5f8b2ee544/\n",
      "    Complete output (2 lines):\n",
      "    /bin/sh: pkg-config: command not found\n",
      "    Failed to find sentencepiece pkgconfig\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/ba/f6/520b56e5977f62aee48833da8b4ff2fdc2b10ebfa0dd78556b1d707d4086/sentencepiece-0.1.91.tar.gz#sha256=f9700cf607ea064d9fad34c751fbf49953dcc56fe68c54b277481aa0aec5c18f (from https://pypi.org/simple/sentencepiece/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25hCollecting transformers<4.0,>=3.1.0\n",
      "  Downloading transformers-3.5.0-py3-none-any.whl (1.3 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 1.3 MB 4.8 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading transformers-3.4.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 3.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers==0.9.2\n",
      "  Downloading tokenizers-0.9.2.tar.gz (170 kB)\n",
      "\u001b[K     |████████████████████████████████| 170 kB 5.1 MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ipython->ktrain) (49.2.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ipython->ktrain) (0.18.0)\n",
      "Requirement already satisfied: appnope in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ipython->ktrain) (0.1.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ipython->ktrain) (3.0.16)\n",
      "Requirement already satisfied: backcall in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ipython->ktrain) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ipython->ktrain) (5.0.5)\n",
      "Requirement already satisfied: pexpect>4.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ipython->ktrain) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ipython->ktrain) (0.7.5)\n",
      "Requirement already satisfied: pygments in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ipython->ktrain) (2.7.4)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from jedi>=0.16->ipython->ktrain) (0.8.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pexpect>4.3->ipython->ktrain) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ktrain) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from traitlets>=4.2->ipython->ktrain) (0.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->ktrain) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->ktrain) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->ktrain) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->ktrain) (1.26.2)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from sacremoses->transformers<4.0,>=3.1.0->ktrain) (7.1.2)\n",
      "Using legacy 'setup.py install' for ktrain, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for seqeval, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for keras-bert, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for keras-transformer, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for keras-embed-sim, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for keras-layer-normalization, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for keras-multi-head, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for keras-self-attention, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for keras-pos-embd, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for keras-position-wise-feed-forward, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for jieba, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for langdetect, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for sacremoses, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for syntok, since package 'wheel' is not installed.\n",
      "Building wheels for collected packages: scikit-learn, tokenizers\n",
      "  Building wheel for scikit-learn (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for scikit-learn: filename=scikit_learn-0.23.2-cp39-cp39-macosx_10_15_x86_64.whl size=6917888 sha256=26e7d34b3e1b2ed5a31ea3f0cccd80af101c10b9f44518cd098cd0acdbcc9952\n",
      "  Stored in directory: /Users/anjaneyatripathi/Library/Caches/pip/wheels/5e/74/24/7e235ccf01765c0daa089c98cc823e9dc1383da5fe0ed7e224\n",
      "  Building wheel for tokenizers (PEP 517) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /Library/Frameworks/Python.framework/Versions/3.9/bin/python3 /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pip/_vendor/pep517/_in_process.py build_wheel /var/folders/sr/f97fk8y57w5_72ntv41mhk8c0000gn/T/tmpwb8s2x_a\n",
      "       cwd: /private/var/folders/sr/f97fk8y57w5_72ntv41mhk8c0000gn/T/pip-install-xpfagqd4/tokenizers_36fce502d6764c2dbc9f4a00b018c7ca\n",
      "  Complete output (37 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib\n",
      "  creating build/lib/tokenizers\n",
      "  copying py_src/tokenizers/__init__.py -> build/lib/tokenizers\n",
      "  creating build/lib/tokenizers/models\n",
      "  copying py_src/tokenizers/models/__init__.py -> build/lib/tokenizers/models\n",
      "  creating build/lib/tokenizers/decoders\n",
      "  copying py_src/tokenizers/decoders/__init__.py -> build/lib/tokenizers/decoders\n",
      "  creating build/lib/tokenizers/normalizers\n",
      "  copying py_src/tokenizers/normalizers/__init__.py -> build/lib/tokenizers/normalizers\n",
      "  creating build/lib/tokenizers/pre_tokenizers\n",
      "  copying py_src/tokenizers/pre_tokenizers/__init__.py -> build/lib/tokenizers/pre_tokenizers\n",
      "  creating build/lib/tokenizers/processors\n",
      "  copying py_src/tokenizers/processors/__init__.py -> build/lib/tokenizers/processors\n",
      "  creating build/lib/tokenizers/trainers\n",
      "  copying py_src/tokenizers/trainers/__init__.py -> build/lib/tokenizers/trainers\n",
      "  creating build/lib/tokenizers/implementations\n",
      "  copying py_src/tokenizers/implementations/byte_level_bpe.py -> build/lib/tokenizers/implementations\n",
      "  copying py_src/tokenizers/implementations/sentencepiece_unigram.py -> build/lib/tokenizers/implementations\n",
      "  copying py_src/tokenizers/implementations/sentencepiece_bpe.py -> build/lib/tokenizers/implementations\n",
      "  copying py_src/tokenizers/implementations/base_tokenizer.py -> build/lib/tokenizers/implementations\n",
      "  copying py_src/tokenizers/implementations/__init__.py -> build/lib/tokenizers/implementations\n",
      "  copying py_src/tokenizers/implementations/char_level_bpe.py -> build/lib/tokenizers/implementations\n",
      "  copying py_src/tokenizers/implementations/bert_wordpiece.py -> build/lib/tokenizers/implementations\n",
      "  copying py_src/tokenizers/__init__.pyi -> build/lib/tokenizers\n",
      "  copying py_src/tokenizers/models/__init__.pyi -> build/lib/tokenizers/models\n",
      "  copying py_src/tokenizers/decoders/__init__.pyi -> build/lib/tokenizers/decoders\n",
      "  copying py_src/tokenizers/normalizers/__init__.pyi -> build/lib/tokenizers/normalizers\n",
      "  copying py_src/tokenizers/pre_tokenizers/__init__.pyi -> build/lib/tokenizers/pre_tokenizers\n",
      "  copying py_src/tokenizers/processors/__init__.pyi -> build/lib/tokenizers/processors\n",
      "  copying py_src/tokenizers/trainers/__init__.pyi -> build/lib/tokenizers/trainers\n",
      "  running build_ext\n",
      "  running build_rust\n",
      "  error: Can not find Rust compiler\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\n",
      "\u001b[?25hSuccessfully built scikit-learn\n",
      "Failed to build tokenizers\n",
      "\u001b[31mERROR: Could not build wheels for tokenizers which use PEP 517 and cannot be installed directly\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# install ktrain\n",
    "!pip3 install ktrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ktrain'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8d53ede856f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# import ktrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mktrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mktrain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ktrain'"
     ]
    }
   ],
   "source": [
    "# import ktrain\n",
    "import ktrain\n",
    "from ktrain import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn, val, preproc = text.texts_from_folder(IMDB_DATADIR, \n",
    "                                          maxlen=500, \n",
    "                                          preprocess_mode='bert',\n",
    "                                          train_test_names=['train', \n",
    "                                                            'test'],\n",
    "                                          classes=['pos', 'neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = text.text_classifier('bert', trn, preproc=preproc)\n",
    "learner = ktrain.get_learner(model,train_data=trn, val_data=val, batch_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit_onecycle(2e-5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
